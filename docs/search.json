[
  {
    "objectID": "ALADYM_tuning_tutorial.html",
    "href": "ALADYM_tuning_tutorial.html",
    "title": "ALADYM_tuning_tutorial",
    "section": "",
    "text": "COISPA Website    COISPA Github"
  },
  {
    "objectID": "ALADYM_tuning_tutorial.html#input-data-requirements",
    "href": "ALADYM_tuning_tutorial.html#input-data-requirements",
    "title": "ALADYM_tuning_tutorial",
    "section": "Input data requirements",
    "text": "Input data requirements\nAfter installation of the ALADYM tuning software, a baseline ALADYM configuration must be prepared. This baseline configuration is the structural reference from which all tuning combinations are generated. Every Tr–Fbar configuration produced by the tuning scripts is a direct modification of this baseline.\nSeveral constraints are critical.\nNatural mortality (M) files must start at age 0. Any offset in age indexing will cause misalignment between biological processes and assessment data, leading to error calculations.\nMissing values in all configuration files must be encoded as NAN, not NA. ALADYM is not NA-aware. Using NA leads to type coercion, failed reads, or numerical propagation of missing values - NAN is explicitly handled by the model and by the tuning scripts.\nThe ALADYM configuration file used here is not the same as the BEMTOOL configuration file. BEMTOOL wraps ALADYM but applies additional preprocessing and abstractions. The tuning workflow operates directly on ALADYM inputs. A template ALADYM configuration file adapted for tuning is provided  here. \n\n\n\n  \n\n\n\nExample ALADYM configuration file.\n\n\nFinally, the simulation period defined in the configuration must match exactly the years available in the assessment time series used for calibration. No extrapolation or truncation is performed automatically."
  },
  {
    "objectID": "ALADYM_tuning_tutorial.html#generation-of-trfbar-combinations",
    "href": "ALADYM_tuning_tutorial.html#generation-of-trfbar-combinations",
    "title": "ALADYM_tuning_tutorial",
    "section": "Generation of Tr–Fbar combinations",
    "text": "Generation of Tr–Fbar combinations\nTr–Fbar tuning is based on a grid search approach. The parameter space is discretised into a finite set of Tr values and Fbar age ranges, and ALADYM is run once for each possible combination.\nThe generation of parameter combinations is handled by the script:\nALADYM_tuning_main_config.R\nThis script reconstructs all mortality-related inputs so that each ALADYM run is internally consistent with the selected Tr–Fbar combination. In practice, the script performs the following operations.\nIt first reads a baseline ALADYM configuration file located in C:\\INPUT\\ALADYM. The script then defines the vectors of Tr values and Fbar age ranges to be explored and builds the full Cartesian product of these parameters.\nFor each Tr–Fbar combination, the script automatically generates three classes of files:\n\nM files, truncated or shifted so that natural mortality starts at the specified Tr value.\nZ files, recalculated to reflect both the selected age-grouping criterion for Fbar and the current Tr value.\nALADYM configuration files, updated so that they reference the correct M and Z files associated with that specific combination.\n\nAll generated configuration files differ from the baseline only in the Tr definition, the Fbar age range, and the mortality file paths. Every other parameter and model setting is inherited unchanged from the baseline configuration.\nNote, the script assumes the following directory structure and requirements:\n\nThe original baseline ALADYM configuration file must be located in C:\\INPUT\\ALADYM.\nSpecies-specific M and F input files must be stored in C:\\INPUT\\ALADYM\\species_folder.\n\nIf fishing mortality at age files are not available, the parameters F_at_age_F and F_at_age_M must be set to “None” in the baseline configuration. In this case, an Fbar_assessment file must be provided. All Z values will then be computed internally from the Fbar assessment data for each Tr–Fbar combination. This can be seen in the following example code.\n## paths\n# input path - main folder where we can find M, F and config_file\nip &lt;- \"C:\\\\INPUT\\\\ALADYM\"\n\n# output path - where you want to save the output (usually C:\\INPUT\\ALADYM)\nop &lt;- \"C:\\\\INPUT\\\\ALADYM\"\n\n# species folder - used for M and F files\nspecies_folder &lt;- \"MUT1718\"\n\n\n# are there different M files for males and females?\nM_different &lt;- TRUE\n\n\n## set the M files names -&gt; make sure these start from age = 0 \n# sex-specific files?\nM_male &lt;- \"M_MUT_M.csv\"\nM_female &lt;- \"M_MUT_F.csv\"\n\n# instead, if they have the same file:\nM_file &lt;- \"M_MUT.csv\"\n\n\n## if F_at_age files exist\nF_at_age_M &lt;- \"F_at_age_MUT_M.csv\"\nF_at_age_F &lt;- \"F_at_age_MUT_F.csv\"\nFbar_assessment &lt;- \"None\"\n\n# otherwise, if there is only an Fbar file coming from the assessment\n# F_at_age_M &lt;- \"None\"\n# F_at_age_F &lt;- \"None\n# Fbar_assessment &lt;- \"Fbar_assessment_MUT.csv\"\n\n## set initial configuration file -&gt; must live in C:\\INPUT\\ALADYM\n## make sure that NA values are specified as NAN (needed for the splitting)\nconfiguration &lt;- \"aladym_MUT_GSA17_18.csv\"\n\n## set tr\ntr = c(0, 1, 2, 3)\n\n## set F_range over which to calculate Fbar, eg: list(c(0,3),c(1,4))\n# if you only have Fbar from assessment, set F_range = None\n\nF_range = list(c(0,1),c(2,3),c(4,5))\n# F_range = \"None\"\n\n\n## time series\nts = c(2004:2024)\n\n## species\nspe = 'MUT'\n\n\nExample of input paths for the creation of different ALADYM configuration files.\n\n\nAll generated files are written automatically to C:\\INPUT\\ALADYM. The naming convention encodes the Tr value and the Fbar age range directly in the filename, allowing each simulation to be uniquely identified and unambiguously traced back to its parameter values.\nTwo examples of the naming convention are as follows:\n\nconfig_run_0_1-3.csv means the configuration file considers tr = 0 and Fbar = (1-3);\nconfig_run_0_assess.csv means the configuration file considers tr = 0 and uses the Fbar range used in the assessment.\n\nOnce ALADYM_tuning_main_config.R has completed execution, no further manual editing of M files, Z files, or configuration files is required."
  },
  {
    "objectID": "ALADYM_tuning_tutorial.html#running-the-trfbar-tuning",
    "href": "ALADYM_tuning_tutorial.html#running-the-trfbar-tuning",
    "title": "ALADYM_tuning_tutorial",
    "section": "Running the Tr–Fbar tuning",
    "text": "Running the Tr–Fbar tuning\nOnce all Tr–Fbar configuration files have been generated, the tuning phase is launched by clicking on the source button in the file\nALADYM_tuning.R.\nThis script operates the full calibration workflow. It iterates sequentially over all Tr–Fbar configuration files created in the previous step by launching ALADYM in batch mode for each configuration without requiring user interaction.\nFor every Tr–Fbar combination, the script extracts annual time series of spawning stock biomass (SSB), Fbar, and total catch from the ALADYM outputs, which are then compared against the corresponding assessment data. Relative errors are computed, and a scalar score is calculated for each combination as the sum of mean squared relative errors across all indicators (see next section)."
  },
  {
    "objectID": "ALADYM_tuning_tutorial.html#outputs-and-diagnostics",
    "href": "ALADYM_tuning_tutorial.html#outputs-and-diagnostics",
    "title": "ALADYM_tuning_tutorial",
    "section": "Outputs and diagnostics",
    "text": "Outputs and diagnostics\nThe calibration score is defined as the sum of mean squared relative errors between simulated and assessment time series for SSB, Fbar, and total catch. For each indicator \\(X\\), the relative error is computed as\n\\[\nErr_t = \\frac{X_t^{sim} - X_t^{obs}}{X_t^{sim}},\n\\] and the total score is\n\\[\nScore = \\frac{1}{T} \\sum_{t=1}^T (Err_t^{SSB})^2 + \\frac{1}{T} \\sum_{t=1}^T (Err_t^{Fbar})^2 + \\frac{1}{T} \\sum_{t=1}^T (Err_t^{Catch})^2.\n\\] The use of squared relative errors ensures scale-independence across indicators with different magnitudes and penalises large deviations more strongly than small ones.\nAll results are accumulated into a single calibration table that links each Tr–Fbar combination to its diagnostic metrics and overall score, found in the Combo_runs_diagnostics folder.\n\n\n\n\nFigure 2 - Calibration table.\n\nIn parallel, the script creates a dedicated output folder for each parameter combination. Each folder contains the full set of diagnostic plots and intermediate results associated with that specific run, allowing post hoc inspection of individual simulations.\nAt the end of the tuning process, the script identifies the Tr–Fbar combination with the lowest total score. This best-performing configuration is recorded in a plain text file that reports the selected Tr value, Fbar age range, and associated score. In addition, two summary output directories are produced: one containing the diagnostics for all tested combinations, and a second containing only the diagnostics associated with the best-performing configuration.\n\n\n\n\nFigure 3 - Example of folders and files created after ALADYM tuning is complete.\n\nAll output folders and files generated by ALADYM_tuning.R are written to the same directory in which the tuning script lives. No automatic cleanup is performed. To maintain an organised project structure, it is recommended to manually create a species-specific folder and move all tuning outputs into that location once the procedure has completed, as shown below:\n\n\n\n\nFigure 4 - Example of species-specific folders to cleanup the repository."
  },
  {
    "objectID": "ALADYM_tuning_tutorial.html#results",
    "href": "ALADYM_tuning_tutorial.html#results",
    "title": "ALADYM_tuning_tutorial",
    "section": "Results",
    "text": "Results\nThe Tr–Fbar tuning example shown in this tutorial uses data for Mullus barbatus (MUT) in GSAs 17–18, originating from an existing case study application. The objective of this example is purely methodological: to demonstrate how the tuning workflow operates and how calibration outputs should be interpreted.\nFor simplicity, all fleet segments were aggregated into a single representative fleet. Consequently, parameter optimisation was performed with respect to total fleet indicators, namely total spawning stock biomass (SSB), total fishing mortality (Fbar), and total catches.\nThe parameter space explored in this example consisted of:\n\nrecruitment timing values\n\n\\[\nTr=\\{0,1,2,3\\},\n\\] - Fbar age ranges \\[\n(0,1), (2,3), (4,5).\n\\] All possible combinations between Tr values and Fbar age ranges were generated and evaluated through the automated grid-search procedure described in the previous sections.\nThe results show the best combo diagnostics plot representing the simulated indicators SSB, F and catch against the observed values. The best performing combo was found to be \\(Tr = 2\\) and \\(Fbar = (4, 5)\\).\n\n\n\n\nFigure 5 - Simulated vs Observed catch for best performing parameters Tr = 2 and Fbar = (4, 5).\n\n\n\n\n\nFigure 6 - Simulated vs Observed F for best performing parameters Tr = 2 and Fbar = (4, 5).\n\n\n\n\n\nFigure 7 - Simulated vs Observed SSB for best performing parameters Tr = 2 and Fbar = (4, 5)."
  },
  {
    "objectID": "ALADYM_tuning_tutorial.html#input-data-requirements-1",
    "href": "ALADYM_tuning_tutorial.html#input-data-requirements-1",
    "title": "ALADYM_tuning_tutorial",
    "section": "Input data requirements",
    "text": "Input data requirements\nThe baseline ALADYM configuration used for selectivity is the same as the one used for the Tr-Fbar tuning with the exception that the Tr and Fbar values must now be set to the identified, best performing Tr-Fbar combination. Consequently, the specified M file should be the one starting at the selected Tr value. Again, we remind that NA values must be encoded as NAN."
  },
  {
    "objectID": "ALADYM_tuning_tutorial.html#generation-of-selectivity-configurations",
    "href": "ALADYM_tuning_tutorial.html#generation-of-selectivity-configurations",
    "title": "ALADYM_tuning_tutorial",
    "section": "Generation of selectivity configurations",
    "text": "Generation of selectivity configurations\nSelectivity configuration generation is more structured than Tr–Fbar tuning because BEMTOOL gives the possibility to choose among six functions for selectivity. Each function is associated therefore to a different subset of parameters.\nThe tuning framework does not attempt to switch between selectivity functions: the selectivity type for each fleet segment is fixed in the original selectivity Excel file and remains unchanged throughout tuning. What is explored are alternative values of the parameters associated with that specific function. This is handled via\nALADYM_tuning_selectivity_main_script.R.\nThe configuration-generation step begins by defining a mapping between selectivity types and the parameters they are allowed to use. This mapping is implemented as a hash map where:\n\nEach key represents a selectivity type identifier.\nEach value is the set of parameter names that are active for that function.\n\nlibrary(hash)\n\n# -----------------------------------------------------\n# Define selectivity dictionary:\n# maps selectivity type -&gt; parameters used\n# -----------------------------------------------------\nselectivity_id &lt;- hash()\nselectivity_id[[\"1\"]] &lt;- list(c(\"param1\", \"param2\"), c(1, 2))\nselectivity_id[[\"2\"]] &lt;- list(c(\"param1\", \"param2\", \"param3\"), c(1, 2, 3))\nselectivity_id[[\"3\"]] &lt;- list(c(\"param1\", \"param2\"), c(1, 2))\nselectivity_id[[\"4\"]] &lt;- list(c(\"param1\", \"param2\"), c(1, 2))\nselectivity_id[[\"5\"]] &lt;- list(c(\"param1\", \"param2\", \"param3\", \"param4\", \"param5\"),\n                              c(1, 2, 3, 4, 5))\nselectivity_id[[\"6\"]] &lt;- list(c(\"param1\", \"param2\", \"param3\"), c(1, 2, 3))\n\n# -----------------------------------------------------\n# Define selectivity parameters combinations per selectivity type\n# -----------------------------------------------------\n# sel 1\np11 &lt;- c(10, 15, 20) #seq(15, 20)\np12 &lt;- c(5, 6) #seq(3, 7)\n\n# sel 2\np21 &lt;- c(10, 15)\np22 &lt;- c(7, 8)\np23 &lt;- c(8, 10)\n\n# sel 3\np31 &lt;- c(20, 25)\np32 &lt;- c(10, 15)\n\n# sel 4\np41 &lt;- c(12, 25)\np42 &lt;- c(6, 7)\np43 &lt;- c(7, 8)\n\n# sel 5\np51 &lt;- c(12, 25)\np52 &lt;- c(12, 25)\np53 &lt;- c(12, 25)\np54 &lt;- c(12, 25)\np55 &lt;- c(12, 25)\n\n# sel 6\np61 &lt;- c(12, 25)\np62 &lt;- c(10, 20)\np63 &lt;- c(15, 15)\n\n\n# per-selectivity-type parameters\nparams_sel &lt;- hash()\nparams_sel[[\"1\"]] &lt;- list(p11, p12)\nparams_sel[['2']] &lt;- list(p21, p22, p23)\nparams_sel[['3']] &lt;- list(p31, p32)\nparams_sel[['4']] &lt;- list(p41, p42, p43)\nparams_sel[['5']] &lt;- list(p51, p52, p53, p54, p55)\nparams_sel[['6']] &lt;- list(p61, p62, p63)\n\n\nExample of how to specify the selectivity parameters range to use in the creation of different ALADYM configuration files.\n\n\nFor example, a logistic function may allow only an inflection age and a slope parameter, whereas a dome-shaped function may allow parameters controlling peak age and curvature. Although the input file contains a fixed number of parameter columns, only the parameters listed in the mapping for the selected type are considered active. The remaining parameter slots are ignored during combination generation and remain fixed at their baseline values.\nDuring configuration creation, the script performs the following sequence:\n\nIt reads the baseline selectivity file and identifies, for each fleet, the assigned selectivity type.\nFor each fleet, it retrieves from the hash map the subset of parameters that are valid for that type.\nIt generates all combinations of the user-defined ranges only for those active parameters.\nIt reconstructs full selectivity files by substituting alternative parameter values fleet by fleet, while keeping:\n\nthe selectivity type unchanged,\nall non-active parameters fixed,\nall other fleets’ parameters unchanged unless explicitly varied.\n\n\nThe result is a set of complete selectivity configuration files in which every fleet retains its original functional form, and only the allowed parameters are varied. Combinations are therefore selectivity-type-specific and fleet-specific. This structure guarantees that a fleet assigned a logistic function will never receive parameters belonging to a dome-shaped function, and no configuration will mix parameter sets incompatible with the declared selectivity type.\nFollowing the remaining steps of ALADYM_tuning_selectivity_main_script.R will create two folders: one folder named selectivity_combinations containing all combinations of the selectivity-specific parameters is created within the specified species folder, whereas the folder of configurations that specify the path of each selectivity file is created in the folder selectivity_configs_SPE, as shown below.\n\n\n\n\nFigure 8 - Example of selectivity configurations output folders.\n\nThese files are then used by the selectivity tuning script, which evaluates their performance against stock- and fleet-level observations."
  },
  {
    "objectID": "ALADYM_tuning_tutorial.html#running-selectivity-tuning",
    "href": "ALADYM_tuning_tutorial.html#running-selectivity-tuning",
    "title": "ALADYM_tuning_tutorial",
    "section": "Running selectivity tuning",
    "text": "Running selectivity tuning\nOnce the configuration files are generated, the selectivity tuning run is launched. For each configuration, ALADYM is executed and the following outputs are extracted:\n\nstock-level indicators (SSB, Fbar, total catch),\nfleet-specific annual catches.\n\nRelative errors are computed both at the stock level and at the fleet level. Fleet errors are retained explicitly rather than collapsed immediately, allowing inspection of trade-offs between fleets.\nIn the same fashion as for the Tr-Fbar tuning, a global score is computed by combining stock-level errors with fleet-level error summaries."
  },
  {
    "objectID": "ALADYM_tuning_tutorial.html#outputs-and-diagnostics-1",
    "href": "ALADYM_tuning_tutorial.html#outputs-and-diagnostics-1",
    "title": "ALADYM_tuning_tutorial",
    "section": "Outputs and diagnostics",
    "text": "Outputs and diagnostics\nSelectivity tuning extends the Tr–Fbar calibration framework by evaluating not only stock-level agreement (SSB, Fbar, total catch) but also fleet-level catch dynamics. The objective is to identify, for each fixed selectivity type, the parameter combination that best fits simulated stock and fleet trajectories with observed data.\nFor each indicator \\(X\\), the stock-level score is computed as before:\n\\[\nScore_{stock} =\n\\frac{1}{T} \\sum_{t=1}^T (Err_t^{SSB})^2\n+\n\\frac{1}{T} \\sum_{t=1}^T (Err_t^{Fbar})^2\n+\n\\frac{1}{T} \\sum_{t=1}^T (Err_t^{Catch})^2.\n\\] In addition, fleet-specific errors are computed for each fleet \\(f\\):\n\\[\nScore_{fleet} =\n\\sum_{f=1}^{F}\n\\frac{1}{T} \\sum_{t=1}^T\n\\left( Err_{t,f}^{Catch} \\right)^2,\n\\] that is, the relative error between simulated fleet-level catch and observed fleet-level catch is calculated and included in the final weighted score:\n\\[\nScore = Score_{stock} + Score_{fleet}.\n\\] This formulation preserves scale independence while ensuring that both stock-level consistency and fleet allocation patterns influence the ranking. Large mismatches in fleet catch distribution are therefore penalised even when aggregate stock dynamics appear satisfactory.\nAll selectivity parameter combinations are accumulated into a cumulative calibration table, stored in the Combo_runs_diagnostics folder. Each row of the table contains:\n\nSelectivity type (fixed per fleet),\nParameter values for active parameters,\nStock-level score,\nFleet-level score,\nFinal weighted score.\n\n\n\n\n\nFigure 9 - Example of selectivity calibration table.\n\nFor each selectivity parameter combination, the script creates a dedicated output folder. Each folder contains:\n\nTime series plots of simulated vs observed SSB,\nTime series plots of simulated vs observed Fbar,\nTime series plots of simulated vs observed total catch,\nFleet-level catch comparisons.\n\nThese folders allow direct inspection of how each selectivity parameterisation alters stock and fleet dynamics.\nAt the end of the process, the script identifies, for each selectivity type present in the model, the parameter combination that minimises the score.\nThe results are saved as:\n\nA plain text file best_sel_combo reporting the best parameter values per selectivity type and a plain text file best_combo_result containing their associated score.\nA Best_combo_diagnostics folder containing diagnostic plots corresponding only to the best-performing configurations.\nA Combo_runs_diagnostics folder containing diagnostics for all tested combinations.\n\n\n\n\n\nFigure 10 - Example of folders and files created after selectivity tuning is complete.\n\nAll output files and folders are written to the same directory in which the selectivity tuning script resides.\nNo automatic cleanup or reorganisation is performed. To maintain a clear structure, it is recommended to create a species-specific folder and manually move the diagnostics folders and the best-parameter text files into that species directory, as shown below.\n\n\n\n\nFigure 11 - Example of species-specific folders used to organise selectivity tuning outputs."
  },
  {
    "objectID": "ALADYM_tuning_tutorial.html#results-1",
    "href": "ALADYM_tuning_tutorial.html#results-1",
    "title": "ALADYM_tuning_tutorial",
    "section": "Results",
    "text": "Results\nA separate example is provided for the selectivity calibration workflow using data for Parapeneus longirostris (DPS) in GSAs 17, 18, 19 and 20.\nIn this case study, three fleets were considered, all sharing the same selectivity formulation. The purpose of the example is to illustrate how selectivity-specific parameter combinations are generated and evaluated rather than to identify biologically optimal values.\nThe fleets were assigned selectivity type 1, which corresponds to a classical ogive selectivity function:\n\\[\nSel(j) = \\frac{1}{1 + e^{\\frac{ln(9)}{SR}(SL_{50\\%} - j)}}.\n\\]\nHere the only selectivity parameters are the length at first capture \\(L_{50\\%}\\) (named \\(p_{11}\\)) and the selectivity range \\(SR = L_{75\\%} - L_{25\\%}\\) (named \\(p_{12}\\)); the tested parameter ranges were:\n\\[\np_{11} = \\{10, 15, 20 \\}, \\ \\newline\np_{12} = \\{5, 6\\}.\\quad\\quad\\quad\n\\]\nThese values were intentionally limited to keep the example compact and computationally light. In practical applications, substantially wider parameter ranges and a larger number of combinations can be explored using the same workflow without modification to the code.\nFor each fleet, named GSA17, GSA18 and GSA19, the best selectivity parameter combination is reported in the plain text file best_sel_combo:\n\n\n\n\nFigure 12 - Best selectivity parameters for each fleet.\n\nThe reported graphs below show the fleet-level simulated catch against observed values for the best fleet-dependent selectivity parameter values.\n\n\n\n\nFigure 13 - Simulated vs Observed catch for fleet GSA17 with best performing parameters.\n\n\n\n\n\nFigure 14 - Simulated vs Observed catch for fleet GSA18 with best performing parameters.\n\n\n\n\n\nFigure 15 - Simulated vs Observed catch for fleet GSA19 with best performing parameters."
  }
]